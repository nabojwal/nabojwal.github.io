<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- original template from from url=(0035)http://www.cs.berkeley.edu/~barron/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
	<meta name="viewport" content="width=800">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
     <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
	
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link rel="icon" type="image/png" href="http://www.cs.berkeley.edu/~barron/seal_icon.png">
	
    <title>Nabojwal Acharjee</title>
    
    <link href="/img/css" rel="stylesheet" type="text/css">
  </head>
  <body>
    <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
      <tbody><tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="68%" valign="middle">
                <p align="center">
                  <name>Nabojwal Acharjee</name>
                  
                </p><p align="">I am a Doctoral Student at Tezpur University, Assam under the joint supervision of <a href="https://agnigarh.tezu.ernet.in/~deepika/">Prof. D. Hazarika</a> and <a href="https://agnigarh.tezu.ernet.in/~vknath/">Prof. V. K. Nath</a>, where my research work entails design and development of deep learning models tailored for Medical Image Computing, specifically disease prediction, classification, image segmentation and anomaly detection etc. During my MTech at <a href="https://nerist.ac.in/">North Eastern Regional Institute of Science and Technology (NERIST), Arunachal Pradesh</a>, I had the oppurtunity to work in the Ray-Bordoloi-Group under the guidence of <a href="https://nerist.ac.in/faculty/dr-ashok-kumar-ray/">Prof. A. K. Ray</a>, where I worked on AlN/Ga<sub>2</sub>O<sub>3</sub>
-based HEMT modelling for RF applications. I received my Bachelors Degree in Electronics and Communication Engineering from <a href="https://nerist.ac.in/">North Eastern Regional Institute of Science and Technology, Arunachal Pradesh</a>. 
</br>
		My current research interest lies at the intersection of Image Processing/Computer Vision and Deep Learning. Lately, I have been working on ViTs, NO, SSMs, GAN & DDPM for mediacl imaging.
		</br>
</br>
		 I am open to research opportunities and eager to contribute to collaborative and interdisciplinary research efforts. I can be reached via <a href="mailto:nabojwal@example.com">email</a>.
		  </br>
	<!--	      Before that, I was a postdoctoral research fellow in <a href="http://disi.unitn.it/~mhug/index.html">Deep Relational Learning</a> group at the University of Trento with Professor <a href="http://disi.unitn.it/~sebe/">Nicu Sebe</a> and a visiting researcher in the CS department at the <a href="https://www.cs.washington.edu/">University of Washington</a> working with <a href="http://homes.cs.washington.edu/~ali/">Ali Farhadi</a>.
I did my PhD at the <a href="http://www.iit.it/">Italian Institute of Technology</a> where I was advised by Professor <a href="http://profs.sci.univr.it/~swan/">Vittorio Murino</a> and also working closely with Professor <a href="http://www0.cs.ucl.ac.uk/staff/m.pontil/">Massimiliano Pontil</a> from University College London.
	    </br></br>
		  I am so delighted to start computer vision research with Professor <a href="https://explorecourses.stanford.edu/instructor/mehrdads">Mehrdad Shahshahani</a> at <a href="http://www.ipm.ac.ir/">IPM Vision Group</a>.
I did my masters in AI and my bachelors in software engineering in Iran.
	  </br>
-->

                </p><p align="center">
<a href="nabojwal@gmail.com">Email</a> &nbsp;/&nbsp;
<!--<a href="./files/Thesis_compressed.pdf">Thesis</a> &nbsp;/&nbsp; -->
<a href="https://scholar.google.com/citations?user=l-GNGx4AAAAJ&hl=en">Google Scholar</a> /&nbsp;
<a href="https://www.linkedin.com/in/nabojwal-acharjee/"> LinkedIn </a> /&nbsp;
<!-- <a href="https://www.csauthors.net/kuldeep-purohit/"> csauthors,net Profile </a> /&nbsp; -->
<a href="./files/cv_nabojwal.pdf"> CV </a>
                </p>
              </td>
              <!--<td width="33%"><img src="./img/moin_pic_cool.jpg"></td>-->
				<td> <img src="./img/nabo_photo.jpg" style="width: 400;"></td></tr> 
          </tbody></table>
 <!--         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
                <heading>Research</heading>
                <p> I work primarily on computer vision, but I am also interested in machine learning and pattern recognition. The central goal of my research is to use vast amounts of data to understand the underlying semantics and structure of visual contents. I am especially interested in learning and recognizing visual object categories and understanding human behaviors. I spent my Ph.D. working on learning mid-level representations for visual recognition (image and video understanding) and now, I am more focused on learning deep neural networks from noisy and incomplete multi-modal data.</p>-->
              <!--<p>My research lies at the intersection of machine learning, computer vision, and natural language processing with an emphasis on learning Deep Neural Networks with minimal supervision and noisy/incomplete multi-modal data.
		      </br></br>
		      <span class="highlight"><strong>Internship Position: </strong> I like working with students. If you're a PhD student interested in a research internship working with me in Berlin, please send me an email with your CV and research interests.</span>
		      </p>
		    </td>
            </tr>
          </tbody></table>
-->
<!--SECTION -->

<!--          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
                <heading>News</heading>

              </td>
            </tr>
          </tbody></table>
-->



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
                <heading>News</heading>
		<p> [2022.11] Selected for the prestigious <strong><a href="https://phd.digitalindia.gov.in/">Visvesvaraya PhD Fellowship, Phase-II</a></strong> funded by <strong>MeitY, Government of India</strong>. </p>
<!-- 		<p> [2024.07] Invited to be an <strong>Area Chair</strong> for <strong><a href="https://wacv2025.thecvf.com/">IEEE/CVF WACV 2025</a></strong>. </p>
		<p> [2024.05] Invited to be a reviewer for <strong><a href="https://neurips.cc/Conferences/2024">NeurIPS 2024</a></strong>. </p>
		<p> [2022.12] Joined <strong><a href="https://about.google/">Google</a></strong> (Mountain View, California) as an <strong>AI/ML Engineer</strong>.</p>		      
		<p> [2022.02] <a href="https://link.springer.com/article/10.1007/s00138-021-01254-x">Paper</a> titled "Multi-planar geometry and latent image recovery from a single motion-blurred image" has been accepted at <strong><a href="https://www.springer.com/journal/138">Machine Vision and Applications Journal</a></strong>.</p>
		<p> [2021.10] Joined <strong><a href="https://www.phiar.net/">Phiar</a></strong> (California) as an <strong>AI Research Scientist</strong>.</p>
		<p> [2021.07] <a href="https://kuldeeppurohit.github.io/spair/">Paper</a> titled "Spatially-Adaptive Image Restoration using Distortion-Guided Networks" has been accepted at <strong><a href="http://iccv2021.thecvf.com/">ICCV 2021</a></strong> (IEEE/CVF International Conference on Computer Vision).</p>
		<p> [2021.07] <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Suin_Distillation-Guided_Image_Inpainting_ICCV_2021_paper.html">Paper</a> titled "Distillation-Guided Image Inpainting" has been accepted at <strong><a href="http://iccv2021.thecvf.com/">ICCV 2021</a></strong> (IEEE/CVF International Conference on Computer Vision).</p>		
		<p> [2021.06] <a href="https://niser.ac.in/scps/news/talk-dr.-kuldeep-purohit/">Invited Talk</a> at the <a href="https://www.niser.ac.in/"> National Institute of Science Education and Research (NISER) Bhubaneshwar</a>.</p>      
		<p> [2021.05] <a href="https://www.youtube.com/watch?v=JzM97t7vUXY/">Invited lecture</a> as a part of Computer Vision Talk series conducted by <a href="https://www.linkedin.com/company/scitech-talks/">SciTech Talks</a>.</p>      
		<p> [2021.03] Invited to be a reviewer for the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). </p>
                <p> [2020.06] Joined as a Post-doctoral Research Associate at the <a href="http://www.cse.msu.edu/">Computer Science and Engineering Department at Michigan State University</a> under <a href="http://hal.cse.msu.edu/team/vishnu-boddeti/">Prof. Vishnu Boddeti</a>.</p>
		<p> [2020.03] Our <a href="https://arxiv.org/abs/2004.05343">paper</a> has been accepted at <strong><a href="http://cvpr2020.thecvf.com/">CVPR 2020</a></strong>, Seattle, USA.</p>
	 	<p> [2020.01] I have been awarded <strong>ACM-India Travel Grant</strong> and <strong>AAAI Scholarship</strong> to present our <a href="https://arxiv.org/abs/1903.11394">paper</a> at <strong><a href="https://aaai.org/Conferences/AAAI-20/">AAAI 2020</a></strong>, New York, USA.</p> 
		<p> [2019.12] Invited to be a reviewer for the IEEE Transactions on Image processing (TIP), IEEE Transactions on Multimedia (TMM) and International Journal of Computer Vision (IJCV) (Springer). </p>
                <p> [2019.12] Invited to present my research at the <strong><a href="http://ncvpripg.kletech.ac.in/cfv.html/">Vision India Track</a></strong> in the National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2019) (Springer). </p>		      
		<p> [2019.11] Our team won the runner up prizes in <strong><a href="http://www.vision.ee.ethz.ch/aim19/">ICCV-AIM 2019</a></strong> Bokeh Effect Challenge and Realistic Image Super-resolution Challenge.</p>		     
		<p> [2019.05] I have been awarded <strong><a href="https://buildyourfuture.withgoogle.com/scholarships/google-travel-scholarships/#!?detail-content-tabby_activeEl=overview">Google Travel Grant</a></strong> to present our <a href="https://arxiv.org/abs/1804.02913">paper</a> at <strong><a href="http://cvpr2019.thecvf.com/">CVPR 2019</a></strong>, Long Beach, CA, USA.</p>
		<p> [2019.04] Our team has claimed <strong><a href="http://www.vision.ee.ethz.ch/ntire19/">1st position in CVPR-NTIRE 2019</a></strong> Image Colorization Challenge. We are also among the finalists in Video Deblurring, Video Superresolution, and Image Dehazing challenges of NTIRE 2019.</p>		      
		<p> [2018.12] Our <a href="./files/ICVGIP2018_Cam.pdf">work</a> is selected for the <strong><a href="https://cvit.iiit.ac.in/icvgip18/bestpaperaward.php">Best Paper Award (Runner Up)</a></strong> in ICVGIP 2018.</p>	
		<p> [2018.08] Our team is among the finalists in all the 3 tracks of <strong><a href="https://pirm2018.org/">ECCV-PIRM 2018</a></strong> Perceptual Image Super-resolution Challenge.</p>	
		<p> [2017.09] Our team secured 13th rank among 4000 participants in the <a href="https://www.hackerearth.com/challenges/competitive/deep-learning-challenge-1/leaderboard/">Hackerearth's Deep Learning based Object Classification Challenge</a>.</p>			      
		<p> [2017.01] Started working as a Research Intern at <a href="https://www.kla-tencor.com/">KLA-Tencor</a>, Chennai.</p>	
                <p> [2016.09] I will be presenting three papers from our lab at <strong><a href="http://www.2016.ieeeicip.org/ICIP%202016/www2.securecms.com/ICIP2016/default.html">ICIP 2016</a></strong>, Phoenix, AZ, USA.</p>		      
		<p> [2016.03] Started working on a sponsored Research Project with <a href="https://www.kla-tencor.com/">NIOT</a>, Ministry of Earth Sciences, Govt. of India.</p>			       -->

              </td>
            </tr>
          </tbody></table>

	  
	  
	  
	  <!--SECTION -->

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
                <heading>Journal Publications and Preprints</heading>
              </td>
            </tr>
          </tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody>
    <tr>	  
      <td width="25%">
        <img src="./img/semiconductors_thumb.png" alt="Semiconductors" width="200" style="border-style: none">
      </td>
      <td width="75%" valign="top">
        <p>
          <a href="https://doi.org/10.1134/S1063782624602632">
            <papertitle>Investigation of High-k Dielectric Passivation Effects on DC Performance of AlN/β–Ga<sub>2</sub>O<sub>3</sub> HEMTs</papertitle>
          </a><br>
          <strong>Nabojwal Acharjee</strong>, S. Singh, A.P. Dadi, et al.<br>
          <strong>Semiconductors, Vol. 59, pp. 452–464 (2025)</strong><br>
          <a href="https://doi.org/10.1134/S1063782624602632">DOI: 10.1134/S1063782624602632</a>
        </p>
        <p>
          This work presents a comprehensive TCAD-based analysis of AlN/β–Ga<sub>2</sub>O<sub>3</sub> HEMTs with various high-k dielectric passivation layers. The study evaluates DC performance enhancements across Si<sub>3</sub>N<sub>4</sub>, Al<sub>2</sub>O<sub>3</sub>, and HfO<sub>2</sub> configurations, highlighting trade-offs in peak current, threshold voltage, and transconductance.
        </p>
        <p>
<!--           <strong>Received:</strong> 02 December 2024 |
          <strong>Revised:</strong> 23 February 2025 |
          <strong>Accepted:</strong> 24 February 2025 |
          <strong>Published:</strong> 13 May 2025 -->
        </p>
      </td>
    </tr>
  </tbody>
</table>

<!----SECTION---->

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
                <heading>Conference Proceedings</heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody><tr>
<!----SECTION---->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
                <heading>Other Projects</heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody><tr>




<!----END PART ---->		    
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody>
    <tr>
      <td>
        <br>
        <p style="text-align: right; font-size: 1em; font-style: italic;">
  	“Science is the poetry of reality.” – Richard Dawkins
	</p>
       <p align="right"><font size="2">
          Thank you for visiting!
        </font></p>
      </td>
    </tr>
  </tbody>
</table>

<!-- Privacy-first analytics with Plausible -->
<script async defer data-domain="nabojwal.github.io" src="https://plausible.io/js/plausible.js"></script>
	    
		    


	<script type="text/javascript" src="//ri.revolvermaps.com/0/0/1.js?i=834fq7qvtyr&amp;s=182&amp;m=0&amp;v=false&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000"align="left" async="async"></script></div>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5fz2vvb1pjx&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
</body></html>
